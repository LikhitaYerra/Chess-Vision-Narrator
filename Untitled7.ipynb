{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from IPython.display import Image\n",
        "from ultralytics import YOLO\n",
        "import logging\n",
        "\n",
        "# Suppress non-critical warnings\n",
        "logging.getLogger().setLevel(logging.ERROR)  # Show only errors, not warnings\n",
        "\n",
        "# Step 1: Verify PyTorch with CUDA\n",
        "print(\"Uninstalling CPU-only PyTorch...\")\n",
        "!pip uninstall torch torchvision -y -q\n",
        "print(\"Installing PyTorch with CUDA...\")\n",
        "!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu124 -q\n",
        "\n",
        "print(f\"Using torch {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_properties(0).name}\")\n",
        "else:\n",
        "    print(\"ERROR: CUDA not available. Stopped.\")\n",
        "    exit()\n",
        "\n",
        "# Step 2: Environment Setup\n",
        "!pip install roboflow -q\n",
        "\n",
        "if not os.path.exists(\"ultralytics\"):\n",
        "    !git clone https://github.com/ultralytics/ultralytics\n",
        "%cd ultralytics\n",
        "!pip install -r requirements.txt -q  # This might fail, but core dependencies are already installed\n",
        "\n",
        "# Download dataset\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YtltN9DWSK5AO0rygbyg\")  # Replace with your API key\n",
        "project = rf.workspace(\"chess-piece-detection-lydqy\").project(\"chess-piece-detection-5ipnt\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov5\")\n",
        "dataset_path = dataset.location\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "# Fix data.yaml paths\n",
        "data_yaml = f\"{dataset_path}/data.yaml\"\n",
        "with open(data_yaml, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "corrected_lines = []\n",
        "for line in lines:\n",
        "    if line.startswith(\"train:\"):\n",
        "        corrected_lines.append(f\"train: {dataset_path}/train/images\\n\")\n",
        "    elif line.startswith(\"val:\"):\n",
        "        corrected_lines.append(f\"val: {dataset_path}/valid/images\\n\")\n",
        "    elif line.startswith(\"test:\"):\n",
        "        corrected_lines.append(f\"test: {dataset_path}/test/images\\n\")\n",
        "    else:\n",
        "        corrected_lines.append(line)\n",
        "\n",
        "with open(data_yaml, \"w\") as f:\n",
        "    f.writelines(corrected_lines)\n",
        "print(f\"Updated {data_yaml} with correct paths\")\n",
        "\n",
        "# Step 3: Train YOLOv8 with Threshold Stopping\n",
        "model = YOLO(\"yolov8s.pt\")\n",
        "target_map50 = 0.99\n",
        "\n",
        "# Train and monitor metrics\n",
        "results = model.train(\n",
        "    data=data_yaml,\n",
        "    epochs=11,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    cache=True,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    name=\"chess_yolov8s_threshold\",\n",
        "    patience=10,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Check metrics after training starts (manual loop not needed, use built-in stopping)\n",
        "# Post-training metric check (in case you want to verify)\n",
        "final_map50 = results.metrics[\"metrics/mAP50(B)\"] if \"metrics/mAP50(B)\" in results.metrics else 0.0\n",
        "print(f\"Final mAP50: {final_map50:.4f}\")\n",
        "if final_map50 >= target_map50:\n",
        "    print(f\"Target mAP50 ({target_map50}) reached: {final_map50:.4f}. Training completed.\")\n",
        "\n",
        "# Step 4: Test YOLOv8\n",
        "test_images_dir = f\"{dataset_path}/test/images\"\n",
        "if os.path.exists(test_images_dir) and os.listdir(test_images_dir):\n",
        "    test_image = f\"{test_images_dir}/{os.listdir(test_images_dir)[0]}\"\n",
        "    weights_path = f\"runs/detect/chess_yolov8s_threshold/weights/best.pt\"\n",
        "    if os.path.exists(weights_path):\n",
        "        results = model.predict(source=test_image, imgsz=640, conf=0.25, save=True)\n",
        "        output_image = f\"runs/detect/predict/{os.path.basename(test_image)}\"\n",
        "        if os.path.exists(output_image):\n",
        "            display(Image(filename=output_image, width=600))\n",
        "        else:\n",
        "            print(f\"Output image not found: {output_image}\")\n",
        "    else:\n",
        "        print(f\"Weights not found: {weights_path}\")\n",
        "else:\n",
        "    print(f\"Test images directory not found or empty: {test_images_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "66GZ9S2ccXic",
        "outputId": "70040a37-c320-4527-cdde-c56d028e9ee3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uninstalling CPU-only PyTorch...\n",
            "Installing PyTorch with CUDA...\n",
            "Using torch 2.6.0+cu124\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n",
            "/content/ultralytics\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dataset downloaded to: /content/ultralytics/Chess-Piece-Detection-2\n",
            "Updated /content/ultralytics/Chess-Piece-Detection-2/data.yaml with correct paths\n",
            "Ultralytics 8.3.96 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/ultralytics/Chess-Piece-Detection-2/data.yaml, epochs=11, time=None, patience=10, batch=16, imgsz=640, save=True, save_period=-1, cache=True, device=0, workers=2, project=None, name=chess_yolov8s_threshold2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/chess_yolov8s_threshold2\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2120692  ultralytics.nn.modules.head.Detect           [12, [128, 256, 512]]         \n",
            "Model summary: 129 layers, 11,140,244 parameters, 11,140,228 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/chess_yolov8s_threshold2', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/ultralytics/Chess-Piece-Detection-2/train/labels.cache... 16706 images, 0 backgrounds, 0 corrupt: 100%|██████████| 16706/16706 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (19.1GB RAM): 100%|██████████| 16706/16706 [00:08<00:00, 1859.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/ultralytics/Chess-Piece-Detection-2/valid/labels.cache... 1592 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1592/1592 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.8GB RAM): 100%|██████████| 1592/1592 [00:01<00:00, 1481.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/chess_yolov8s_threshold2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/chess_yolov8s_threshold2\u001b[0m\n",
            "Starting training for 11 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/11      3.68G        1.5      1.512      1.137          6        640: 100%|██████████| 1045/1045 [04:34<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.758      0.787      0.829      0.496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/11      4.47G      1.415     0.7713       1.12         30        640: 100%|██████████| 1045/1045 [04:32<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.901      0.896      0.954      0.635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/11      4.48G      1.311     0.6479      1.074         33        640: 100%|██████████| 1045/1045 [04:29<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.949      0.932      0.975      0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/11      4.48G      1.248     0.5829      1.046         64        640: 100%|██████████| 1045/1045 [04:28<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.957      0.948      0.982      0.696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/11      4.48G      1.201      0.541      1.026         23        640: 100%|██████████| 1045/1045 [04:29<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.965      0.957      0.984      0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/11      4.48G      1.163     0.5057      1.013         33        640: 100%|██████████| 1045/1045 [04:29<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.974      0.964      0.987      0.743\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/11      4.48G      1.127     0.4814      1.004         15        640: 100%|██████████| 1045/1045 [04:30<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.976       0.97      0.989      0.737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/11      4.48G      1.093     0.4571     0.9893          2        640: 100%|██████████| 1045/1045 [04:29<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.978      0.974       0.99      0.749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/11      4.52G       1.07     0.4392     0.9847         10        640: 100%|██████████| 1045/1045 [04:29<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400       0.98      0.975       0.99       0.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/11      4.55G      1.038     0.4231     0.9715          2        640: 100%|██████████| 1045/1045 [04:29<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.983       0.98      0.991       0.77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/11      4.59G      1.007     0.4056     0.9616         55        640: 100%|██████████| 1045/1045 [04:29<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:13<00:00,  3.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.984       0.98      0.991      0.778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "11 epochs completed in 0.870 hours.\n",
            "Optimizer stripped from runs/detect/chess_yolov8s_threshold2/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/chess_yolov8s_threshold2/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/chess_yolov8s_threshold2/weights/best.pt...\n",
            "Ultralytics 8.3.96 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 11,130,228 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 50/50 [00:19<00:00,  2.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1592      30400      0.984       0.98      0.991      0.778\n",
            "          black-bishop        976       1854      0.987      0.969      0.991      0.766\n",
            "            black-king       1030       1036      0.976      0.979      0.992      0.808\n",
            "          black-knight       1012       1861      0.984      0.986      0.991      0.763\n",
            "            black-pawn       1052       7351      0.997      0.988      0.995      0.759\n",
            "           black-queen        970        988      0.969      0.967      0.989      0.804\n",
            "            black-rook        987       1823       0.98      0.983       0.99      0.766\n",
            "          white-bishop       1054       1941      0.992      0.985      0.993      0.774\n",
            "            white-king       1102       1107      0.973       0.97       0.99      0.811\n",
            "          white-knight       1081       1985      0.991      0.993       0.99      0.761\n",
            "            white-pawn       1042       7387      0.994      0.992      0.994       0.75\n",
            "           white-queen       1058       1098      0.974      0.964      0.985      0.801\n",
            "            white-rook       1054       1969      0.989      0.984      0.992      0.769\n",
            "Speed: 0.2ms preprocess, 4.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/chess_yolov8s_threshold2\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DetMetrics' object has no attribute 'metrics'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n        names (dict): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n    ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-62131a517a9c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m# Check metrics after training starts (manual loop not needed, use built-in stopping)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;31m# Post-training metric check (in case you want to verify)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mfinal_map50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metrics/mAP50(B)\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"metrics/mAP50(B)\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Final mAP50: {final_map50:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfinal_map50\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtarget_map50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;34m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{name}' object has no attribute '{attr}'. See valid attributes below.\\n{self.__doc__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DetMetrics' object has no attribute 'metrics'. See valid attributes below.\n\n    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP).\n\n    Attributes:\n        save_dir (Path): A path to the directory where the output plots will be saved.\n        plot (bool): A flag that indicates whether to plot precision-recall curves for each class.\n        names (dict): A dictionary of class names.\n        box (Metric): An instance of the Metric class for storing detection results.\n        speed (dict): A dictionary for storing execution times of different parts of the detection process.\n        task (str): The task type, set to 'detect'.\n    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil, os\n",
        "\n",
        "# Define save directory\n",
        "save_dir = \"/content/drive/My Drive/Chess_Model\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save weights\n",
        "weights_path = \"/content/ultralytics/runs/detect/chess_yolov8s_threshold2/weights/best.pt\"\n",
        "shutil.copy(weights_path, f\"{save_dir}/best.pt\")\n",
        "shutil.copy(weights_path.replace(\"best.pt\", \"last.pt\"), f\"{save_dir}/last.pt\")\n",
        "\n",
        "# Save logs\n",
        "log_path = \"/content/ultralytics/runs/detect/chess_yolov8s_threshold2/results.csv\"\n",
        "if os.path.exists(log_path):\n",
        "    shutil.copy(log_path, f\"{save_dir}/results.csv\")\n",
        "\n",
        "print(f\"Saved to {save_dir}: {os.listdir(save_dir)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Pxuba5sEW1J",
        "outputId": "5b26c7e4-9600-4c96-84b2-020d1fbc8b16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Saved to /content/drive/My Drive/Chess_Model: ['best.pt', 'last.pt', 'results.csv']\n"
          ]
        }
      ]
    }
  ]
}